<html>
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-167528382-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>


    
    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

    <title>Memo</title>
    
    
    <meta content="Memo" name="keywords">
    
    <meta content="Memo - Problem for Pose Estimation (1) 一張圖片裡有多少人，而這些人擺什麼姿勢和人的大小？
(2) 有幾個人是相互疊在一起（overlap）的，他們彼此摭蓋面積？
(3) 無法即時（realtime）
另外論文中也提到了一些現有方法存在的瓶頸，現有方法主要是透過 top-down 的方式：
person detector
single-person pose estimation 來解決此類問題，而這很依賴效能，如果 person detector 失敗了
Key point 文章的核心是提出一种利用Part Affinity Fields（PAFs）的自下而上的人体姿态估计算法。
(1) 研究自下而上算法（得到关键点位置再获得骨架）
(2) 而不是自上而下算法（先检测人，再回归关键点) 是因为后者运算时间会随着图像中人的个数而显著增加，而自下而上所需计算时间基本不变。 所以時間不會隨著人變多而有影響
Main Flow (1) 讀進一張圖片大小為 w×h 的圖片 I。
(2) 送進 model VGG-19 的前 10 層 layer train 出大小一樣為 w×h 的 features F。
(3) 再送進 paper 中提到的 model，會得到以下兩個：
(4) 再將 confidence maps S 和 affinity fields L 送到 greedy inference，就能產生所有人的 2D keypoints。" name="description">
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    
    

    

    
        <script async src="https://www.googletagmanager.com/gtag/js?id=UA-167528382-1"></script>
        <script>
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments)};
          gtag('js', new Date());
          gtag('config', 'UA-167528382-1');
        </script>
    

    
    
    <script async src="https://cdn.jsdelivr.net/npm/mathjax@3.0.5/es5/tex-mml-chtml.js" integrity="sha256-HGLuEfFcsUJGhvB8cQ8nr0gai9EucOOaIxFw7qxmd+w=" crossorigin="anonymous"></script>
    

    <link rel="stylesheet" href="/layui/css/layui.css">
    <link rel="stylesheet" href="/self/css/default.css">
    <script async src="/layui/layui.js"></script>

    <link rel="stylesheet" async href="/self/css/markdown.min.css">
    <link rel="stylesheet" async href="/self/css/gallery.css">
    
    
    

    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css" integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin="anonymous">
    <script async src="https://cdn.jsdelivr.net/npm/lazysizes@5.2.0/lazysizes.min.js" integrity="sha256-h2tMEmhemR2IN4wbbdNjj9LaDIjzwk2hralQwfJmBOE=" crossorigin="anonymous"></script></head>

<body>
    
    <header class="layui-header layui-bg-cyan">

    
    
    <a class="nav-self-logo" href="/">
        Memo
    </a>

    <ul class="layui-nav layui-layout-right layui-bg-cyan" lay-filter="">
        
        
        <li class="layui-nav-item" id="nav_big"><a href="/post/">Posts</a></li>
        

        
            
                <li class="layui-nav-item" id="nav_big"><a href="/about/">About</a></li>
            
        

        
        <li class="layui-nav-item" id="nav_small">
            <a href="javascript:;">
                <i class="layui-icon layui-icon-app" style="font-size: 24px;"></i>
            </a>

            <dl class="layui-nav-child">
                
                <dd><a href="/post/">Posts</a></dd>
                

                
                    
                        <dd><a href="/about/">About</a></dd>
                    
                
            </dl>
        </li>
    </ul>
</header>

<script>
layui.use('element', function(){
  var element = layui.element;
});
</script>
        <div id="content" style="min-height:80%">
<h5 id="wc" style="font-size: 1rem;text-align: center;">300 Words|Read in about 2 Min|total read<span id="busuanzi_value_page_pv"></span></h5>

<div class="layui-container" style="margin-bottom: 10px">
    

    <div class="layui-row layui-col-space10">
        <div class="layui-col-md12 layui-col-sm12 layui-col-xs12">
            <div class="layui-card single-card">
                <br />
                <blockquote class="self-elem-quote self-elem-quote-bg-red markdown-body single-title" >
                    <h1></h1>
                    <h3 style="margin-top:10px; margin-bottom:10px"> 
    <i class="layui-icon layui-icon-date" style="font-size: 28px; vertical-align: -2px;"></i>
    <span>0001-01-01</span>

    
     
    <i class="layui-icon layui-icon-list" style="font-size: 32px; vertical-align: -3px;"></i>
    

    
        <a href="/categories/alg-openpose/">
            <span class="layui-badge layui-bg-orange" style="vertical-align: 2px;">ALG-OpenPose</span>
        </a>
    

    
    
    
</h3>
                </blockquote>
                <div class="layui-card-body markdown-body single-content">
                    <h1 id="problem-for-pose-estimation">Problem for Pose Estimation</h1>
<p>(1) 一張圖片裡有多少人，而這些人擺什麼姿勢和人的大小？<br>
(2) 有幾個人是相互疊在一起（overlap）的，他們彼此摭蓋面積？<br>
(3) 無法即時（realtime）<br>
另外論文中也提到了一些現有方法存在的瓶頸，現有方法主要是透過 top-down 的方式：<br>
person detector<br>
single-person pose estimation  <br>
來解決此類問題，而這很依賴效能，如果 person detector 失敗了</p>
<h1 id="key-point">Key point</h1>
<p>文章的核心是提出一种利用Part Affinity Fields（PAFs）的自下而上的人体姿态估计算法。<br>
(1) 研究自下而上算法（得到关键点位置再获得骨架）<br>
(2) 而不是自上而下算法（先检测人，再回归关键点)  <br>
是因为后者运算时间会随着图像中人的个数而显著增加，而自下而上所需计算时间基本不变。 <br>
所以時間不會隨著人變多而有影響</p>
<h1 id="main-flow">Main Flow</h1>
<p>(1) 讀進一張圖片大小為 w×h 的圖片 I。<br>
(2) 送進 model VGG-19 的前 10 層 layer train 出大小一樣為 w×h 的 features F。<br>
(3) 再送進 paper 中提到的 model，會得到以下兩個：<br>
<img src="../https://github.com/evansin100/OpenPose/blob/master/Selection_007.png" alt="image"><br>
(4) 再將 confidence maps S 和 affinity fields L 送到 greedy inference，就能產生所有人的 2D keypoints。</p>
<h1 id="confidence-map-and-affinity-fields">Confidence map and affinity fields</h1>
<p><img src="../https://github.com/evansin100/OpenPose/blob/master/Selection_008.png" alt="image"><br>
Fig. 3 給出了模型示意圖，圖片輸入進去，然後同時預測出 confidence maps S 和 affinity fields L。<br>
神經網路分成兩個部分：<br>
上方淺橘色部分預測 confidence map<br>
下方淺藍色部分預測 affinity fields<br>
每個分支都是一個遞迴的預測結構，整個 model 包含了 T 個 stage，<br>
每個 stage 中都加入中間監督（intermediate supervision），<br>
這是用來處理 vanishing gradient 的問題。<br>
<img src="../https://github.com/evansin100/OpenPose/blob/master/Selection_009.png" alt="image"><br>
<img src="../https://github.com/evansin100/OpenPose/blob/master/Selection_010.png" alt="image"><br>
在預測的 predictions 和 groundtruth maps and fileds 使用了 loss function L2，<br>
論文中特別提到 loss functions 是隨著空間而變的（spatially），因為有些 datasets 不見得會完整地標示所有人</p>
<h1 id="details--confidence-maps-for-part-detection">Details : Confidence Maps for Part Detection</h1>
<p>下邊給出根據 annotation 計算 groundtruth confidence maps S∗ 的方法，
每個 confidence map 都是一個 2D 的表示。理想情況下，<br>
(1) 當圖片中只包含一個人時：<br>
如果一個 keypoint 是可見的話，對應的 confidence map 中只有一個峰值。<br>
(2) 當圖片中有多個人時：<br>
對於每一個人 k 的每一個可見 keypoint j，在對應的 confidence map 中都會有一個峰值</p>
<p>詳細方法如下：<br>
先找出每個人 k 的某一部位 j<br>
每一個人 k 的單個 confidence maps S∗j,k 和<br>
xj,k∈R2 表示圖片中人 k 的 part j 對應的 groundtruth position<br>
計算方式如式 (6) 所示，其中 σ 用來控制峰值在 confidence map 中的傳播範圍。</p>
<p>再找出所有人的部位 j，這裡取最大值而不是平均值能夠更準確地將同一個 confidence map 中的峰值保存下來，<br>
即：對整張圖 w×h 每一個點，找該點在所有人之中的最大值！</p>
<h1 id="details--part-afﬁnity-fields-for-part-association">Details : Part Afﬁnity Fields for Part Association</h1>
<p>給定一組 keypoints，如 Fig.5(a) 所示，我們如何把它們組裝成，未知數量人的整個身體的 pose 呢？</p>
<h5 id="我們需要一個好方法來確定每對-keypoints-之間的連接即它們屬於同一個人">我們需要一個好方法來確定每對 keypoints 之間的連接，即：它們屬於同一個人。</h5>
<p>一個可能的方法是找到一個位於每一對 keypoints 之間的一個中間點，<br>
後檢查中間點是真正的中間點的機率，如 Fig. 5(b) 所示。但是當人們擠在一起時，<br>
中間點可能是錯誤的連線，如 Fig. 5(b) 中綠線所示。出現這種情況的原因有兩個：<br>
(1) 這種方式只編碼了位置資訊，沒有方向<br>
(2) 身體的支撐區域已經縮小到一個點上。</p>
<h5 id="為解決這些限制我們提出了稱為-pafpart-affinity-fields-的特徵">為解決這些限制，我們提出了稱為 PAF(part affinity fields) 的特徵</h5>
<h5 id="表示來保存身體的支撐區域的位置信息和方向信息">表示來保存身體的支撐區域的位置信息和方向信息，</h5>
<p>如 Fig. 5(c) 所示。對於每一條軀幹來說，the part affinity 是一個 2D 的向量區域。<br>
在屬於一個軀幹上的每一像素都對應一個 2D 的向量，這個向量表示軀幹上從一個 keypoint 到另一個 keypoint 的方向。<br>
<img src="../https://github.com/evansin100/OpenPose/blob/master/Selection_011.png" alt="image"></p>
</div>
            </div>
        </div>

        
    </div>
</div>


        </div><footer>
    

    <span id="busuanzi_container_site_pv">
        total vistor：<span id="busuanzi_value_site_pv"></span>
    </span>
    &nbsp;
    <span id="busuanzi_container_site_uv">
        you are <span id="busuanzi_value_site_uv"></span> th visitor
    </span>

    <div class="layui-container">
        <div class="layui-row">
            <div class="layui-col-md4 layui-col-sm6 layui-col-xs6">
                <h3> Related Sites </h3>
            </div>
        </div>
        <div class="layui-row">
            
            <div class="layui-col-md4 layui-col-sm6 layui-col-xs12">
                <a href="/"><p class="footer-url">home</p></a>
            </div>
            
            <div class="layui-col-md4 layui-col-sm6 layui-col-xs12">
                <a href="/about/"><p class="footer-url">About</p></a>
            </div>
            
        </div>
    </div>
    
    
    <div class="layui-container">
        <p class="copyright">&copy; All rights reserved. Powered by <a href='https://gohugo.io' style='color:#FFFFFF'>Hugo</a> and <a href='https://github.com/ertuil/erblog' style='color:#FFFFFF'>Erblog</a>.</p>
    </div>
</footer>

</body>
</html>
