<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>SW-OP-Deconv on Memo</title>
    <link>https://evansin100.github.io/categories/sw-op-deconv/</link>
    <description>Recent content in SW-OP-Deconv on Memo</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    
	<atom:link href="https://evansin100.github.io/categories/sw-op-deconv/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title></title>
      <link>https://evansin100.github.io/post/sw-op-deconv/readme/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://evansin100.github.io/post/sw-op-deconv/readme/</guid>
      <description>Concept  deconvolution并不是个好名字，因为它存在歧义： before (感覺有從模糊變回清楚的感覺)  deconvolution最初被定义为“inverse of convolution”或者“inverse filter”或者“解卷积”，是指消除先前滤波作用的方法。 比如，我们认为原始图像是清晰的，但是通过透镜观测到的图像却变得模糊，如果假设透镜的作用相当于以某个kernel作用在原始图像上， 由此导致图像变得模糊，那么根据模糊的图像估计这个kernel或者根据模糊图像恢复原始清晰图像的过程就叫deconvolution   after (correct naming), 只是說反像操作  又重新定义了deconvolution，实际上与transposed convolution、sub-pixel or fractional convolution指代相同。 transposed convolution是一个更好的名字，sub-pixel or fractional convolution可以看成是transposed convolution的一个特例。 对一个常规的卷积层而言，前向传播时是convolution，将input feature map映射为output feature map， 反向传播时则是transposed convolution，根据output feature map的梯度计算出input feature map的梯度，梯度图的尺寸与feature map的尺寸相同。    Comparison  tensorflow =&amp;gt; input padding caffe =&amp;gt; GEMM + col2im 傳統deconv and ncnn =&amp;gt; 有人說是 direct conv
=&amp;gt; 看起來不同的實作算出來的答案會不同 e.g.,padding or direct conv  </description>
    </item>
    
  </channel>
</rss>