<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ALG-Reinforcement_Learning on Memo</title>
    <link>https://evansin100.github.io/categories/alg-reinforcement_learning/</link>
    <description>Recent content in ALG-Reinforcement_Learning on Memo</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    
	<atom:link href="https://evansin100.github.io/categories/alg-reinforcement_learning/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title></title>
      <link>https://evansin100.github.io/post/alg-reinforcement_learning/readme/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://evansin100.github.io/post/alg-reinforcement_learning/readme/</guid>
      <description>Key Example 建議看這個範例
了解怎麼做到reinforcement learning的簡單訓練方式
以及再一開始不會玩的時候,怎麼做random action
https://github.com/evansin100/ALG-Reinforcement_Learning/tree/master/3_Gym/Cartpole-tf-keras
如果想了解怎麼建構一個env(不靠Gym)
則可以看這篇(Maze)
可以看這邊 有完整的Depp reinformance learning的範例(包含training)
https://github.com/evansin100/ALG-Reinforcement_Learning/tree/master/2_Deep-Q-Learning/Maze_Example youtube教學 https://morvanzhou.github.io/tutorials/machine-learning/reinforcement-learning/
Summary  訓練資料必需有input跟label(答案)， 讓機器去mapping出一個最好的模型，常用的演算法為分類、回歸等演算法   訓練資料只有input沒有label(答案)， 讓機器從訓練資料中找出規則，常用的演算法為集群演算法   從現在的環境來決定行為，是一種互動式的學習過程 =&amp;gt; 根據環境, 是一種互動式的學習 強化學習其實就是訓練一個AI 可以通過每一次的錯誤來學習，就跟我們小時候學騎腳踏車一樣， 一開始學的時候會一直跌倒，然後經過幾次的失敗後，我們就可以上手也不會跌倒了 強化式學習的特徵是訓練必須要有正負回報(positive/negative reward)， 在訓練過程中，模型會根據不同的狀況(state)嘗試各種決定(action)， 再根據此決定得到的結果內化吸收， 下方的AI 玩 Mario遊戲影片便是一種應用，在模型最初時， 可以看到角色就是站在原地閒置太久，拿到了負面回報， 所以它改變開始學習向前移動，走了一段路之後被棒球K到，它又得到了負面回報， 所以它開始加上跳躍來閃避傷害，最後最後，破關方式就被電腦試了出來。  Application (RL) 一般人聽到RL，可能只想到Alpha Go，或是使用在遊戲上面，但其實RL現在已經開始有很多的應用了。
=&amp;gt;對話系統：有些已經把RL用在對話系統上，利用互動式學習，隨著時間不斷的提升對話系統
=&amp;gt;醫療：利用RL來尋找最佳的治療方案
=&amp;gt;Google auto ML： 使用RL來為計算機視覺和語言建模生成神經網路架構
=&amp;gt;自動駕駛
Application (RL+GAN) 一般reinformance learning都是學人的practice來得到相關的設定怎麼下
但其實也可以透過學機器的方式,也就是生成網路
生成網路有兩個部份: (1) generator(生成), (2) descriminator(辨識）</description>
    </item>
    
  </channel>
</rss>